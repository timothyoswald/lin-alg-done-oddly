\chapter{Spectral Theory}

\oldsection{Eigenvalues and Eigenvectors}
Here we will only consider linear transformations $T_A:V\to V$ via $T_A(\vec{x})=A\vec{x}$. The motivation behind this chapter is the fact that often times we need to repeatedly apply linear transformations. This means that we need to compute $A^n\vec{x}$, but this is an expensive computation since matrix multiplication is not trivial to compute. In this chapter, we will analyze when we have "nicer" ways to compute $A^n\vec{x}$ and to what extent we can determine
\begin{definition}
    Let $A$ be a $n\times n$ matrix. Assume that we have $A\vec{x}=\lambda\vec{x}$ for $\vec{x}\in V$ and $\lambda\in\mathbb{F}$. We call $\lambda$ an eigenvalue of $A$ and $\vec{x}$ the corresponding eigenvector. $\vec{0}$ is not considered an eigenvector.
\end{definition}
Let's analyze when we have a solution for $A\vec{x}=\lambda\vec{x}$.
\begin{align*}
    A\vec{x}&=\lambda\vec{x}\\
    A\vec{x}-\lambda\vec{x}&=\vec{0}\\
    A\vec{x}-\lambda I\vec{x}&=\vec{0}\\
    (A-\lambda I)\vec{x}&=\vec{0}
\end{align*}
If $A-\lambda I$ is invertible, then this equation has exactly one solution: the zero vector. We require that eigenvectors are non-zero so we care about the solutions when $A-\lambda I$ is not invertible. As we know, this is equation has nontrivial solutions exactly when $det(A-\lambda I)=0$.
\begin{example}
    Let $A=\begin{bmatrix}
        2 & 1 \\
        1 & 2
    \end{bmatrix}$. We have that $A-\lambda I=\begin{bmatrix}
        2 - \lambda & 1\\
        1 & 2 - \lambda
    \end{bmatrix}$ and $det(A-\lambda I)=(2-\lambda)^2-1$.
    \begin{align*}
        (2-\lambda)^2-1&=0\\
        4-4\lambda+\lambda^2-1&=0\\
        \lambda^2-4\lambda+3&=0\\
        (\lambda -3)(\lambda-1)&=0
    \end{align*}
    This tells us that $1$ and $3$ are eigenvalues for $A$. Now, let's find their corresponding eigenvectors. First, let $\lambda=1$.
    \begin{align*}
        A\vec{x}&=\lambda\vec{x}\\
        A\vec{x}&=\vec{x}\\
        \begin{bmatrix}
            2 & 1\\
            1 & 2
        \end{bmatrix}\begin{bmatrix}
            x_1 \\ x_2
        \end{bmatrix}&=\begin{bmatrix}
            x_1 \\ x_2
        \end{bmatrix}
    \end{align*}
    This gives us the equations $2x_1+x_2=x_1$ and $x_1+2x_2=x_2$. These tell us that $x_1=-x_2$. Moreover, any vector that satisfies $\begin{bmatrix}
        a \\ -a
    \end{bmatrix}$ is an eigenvector of $A$ with eigenvalue $1$.
\end{example}
\begin{definition}
    When finding eigenvalues, we call the equation $det(A-\lambda I)$ the characteristic polynomial.
\end{definition}
\begin{example}
    Let $T: \mathbb{P}^n\to\mathbb{P}^n$ be the derivative operator. What are the eigenvalues of $T$?

    First, we notice that if the input has degree $k\geq 1$, then the output has degree $k-1$. There is no way to scale a degree $k-1$ polynomial by a constant to get a degree $k$ polynomial thus there are no eigenvalues for polynomials of degree $k\geq 1$.

    This leaves the case when $k<1$. When $k<1$, our polynomial is simply a constant. The derivative of a constant is just $0$. Thus, this tells us that $T$ has eigenvalue $0$ which has eigenvectors that are any constant.
\end{example}
\section{Diagonalization}
We previously discussed taking large powers of $A$. This can be very expensive especially if $A$ is high dimensional. However, if we have the special case where $A$ is diagonal, this computation is really easy since:
$$\begin{bmatrix}
    a & 0 & 0\\
    0 & b & 0\\
    0 & 0 & c
\end{bmatrix}\begin{bmatrix}
    a & 0 & 0\\
    0 & b & 0\\
    0 & 0 & c
\end{bmatrix}=\begin{bmatrix}
    a^2 & 0 & 0\\
    0 & b^2 & 0\\
    0 & 0 & c^2
\end{bmatrix}$$
Moreover, by induction we can see that:
$$\begin{bmatrix}
    a & 0 & 0\\
    0 & b & 0\\
    0 & 0 & c
\end{bmatrix}^n=\begin{bmatrix}
    a^n & 0 & 0\\
    0 & b^n & 0\\
    0 & 0 & c^n
\end{bmatrix}$$
\begin{definition}
    $T:V\to V$ is diagonalizable if there exists a basis $B$ for $V$ consisting of eigenvectors of $T$. Let $B=(\vec{v}_1,\ldots,\vec{v}_n)$ with corresponding eigenvalues $\lambda_1,\ldots,\lambda_n$ then:
    $$[T]_{B\to B}=\begin{bmatrix}
        \lambda_1 & 0 & 0 & 0\\
        0 & \lambda_2 & 0 & 0\\
        \vdots & \vdots & \vdots & \vdots\\
        0 & 0 & 0 & \lambda_n
    \end{bmatrix}$$
\end{definition}
Let's consider where this matrix comes from. We know that the first column of the matrix is equal to $[T(\vec{v}_1)]_B$. We also know that since $\vec{v}_1$ is an eigenvector, that $T(\vec{v}_1)=\lambda_1\vec{v}_1$. This gives us that $T(\vec{v}_1)=\lambda_1\vec{v}_1+0\vec{v}_2+0\vec{v_3}+\ldots+0\vec{v}_n$. This gives us the coordinate vector shown in the first column of the above matrix. You can apply similar logic to the rest of the columns.

Now, let's talk about how do we find this diagonal matrix. Based on the definition, we could find every single eigenvector and then check if they form a basis. If not, then $T$ is not diagonalizable. Otherwise, let's look at how we get $[T]_{B\to B}$. If we want, $[T]_{B\to B}$ we need to use change of basis matrices:
$$[T]_{B\to B}=[I]_{E\to B}[T]_{E\to E}[I]_{B\to E}$$
Note that $E$ represents the elementary basis. Note that initially, we only know $[T]_{E\to E}$.
\begin{align*}
    [T]_{B\to B}&=[I]_{E\to B}[T]_{E\to E}[I]_{B\to E}\\
    [I]_{E\to B}^{-1}[T]_{B\to B}&=[I]_{E\to B}^{-1}[I]_{E\to B}[T]_{E\to E}[I]_{B\to E}\\
    [I]_{E\to B}^{-1}[T]_{B\to B}&=[T]_{E\to E}[I]_{B\to E}\\
    [I]_{E\to B}^{-1}[T]_{B\to B}[I]_{B\to E}^{-1}&=[T]_{E\to E}[I]_{B\to E}[I]_{B\to E}^{-1}\\
    [I]_{E\to B}^{-1}[T]_{B\to B}[I]_{B\to E}^{-1}&=[T]_{E\to E}\\
    [I]_{B\to E}[T]_{B\to B}[I]_{E\to B}&=[T]_{E\to E}
\end{align*}
A common way this is notated is $P^{-1}DP=A$. Let's talk about why this achieves the efficient power multiplication that want.
\begin{align*}
    ([T]_{E\to E})^2&=([I]_{B\to E}[T]_{B\to B}[I]_{E\to B})^2\\
    &=([I]_{B\to E}[T]_{B\to B}[I]_{E\to B})([I]_{B\to E}[T]_{B\to B}[I]_{E\to B})\\
    &=([I]_{B\to E}[T]_{B\to B}[T]_{B\to B}[I]_{E\to B})\\
    &=([I]_{B\to E}[T]_{B\to B}^2[I]_{E\to B})
\end{align*}
This gives us that:
$$([T]_{E\to E})^n=[I]_{B\to E}[T]_{B\to B}^n[I]_{E\to B}$$
Since $[T]_{B\to B}$ is diagonal, this computation is simple.