\chapter{Determinants}

\oldsection{Determinants}
We know that matrices are a nice way to represent abstract linear transformation. In fact, they are so nice that they give rise to another way to understand linear transformations in the sense of determinants. By default, we can draw a coordinate plane over $\R^2$ by letting our elementary basis vectors $(1,0)$ and $(0,1)$ form grid lines. Consider an arbitrary linear transformation $T$ over $\R^2$. This linear transformation moves $(1,0)$ and $(0,1)$ somewhere and at the same time, shifts how our grid lines look. We can draw a new grid with $T(1,0)$ and $T(0,1)$ as the lines. Determinants give us a way to capture how the "area" of the squares in this grid line changed.

Let $A$ be a $n\times n$ matrix where $A=[\vec{c}_1,\ldots,\vec{c}_n]$.
\begin{enumerate}
    \item $det(I_n)=1$ (Normalization)
    \item $det(\vec{c}_1,\ldots,\vec{c}_i,\ldots,\vec{c}_j,\ldots,\vec{c}_n)=-det(\vec{c}_1,\ldots,\vec{c}_j,\ldots,\vec{c}_i,\ldots,\vec{c}_n)$ (Antisymmetry)
    \item $det(\vec{c}_1,\ldots,
    \alpha\vec{c}_i+\vec{v},\ldots,\vec{c}_n)=\alpha det(\vec{c}_1,\ldots,
    \vec{c}_i,\ldots,\vec{c}_n)+det(\vec{c}_1,\ldots,
    \vec{v},\ldots,\vec{c}_n)$ (Multilinearity)
\end{enumerate}
\begin{example}
    Let $A=\begin{bmatrix}
        a & b \\
        c & d
    \end{bmatrix}$.
    \begin{align*}
        det(A)&=det(\begin{bmatrix}
        a & b \\
        c & d
    \end{bmatrix})\\
    &=det(\begin{pmatrix}
        a \\ c
    \end{pmatrix}, \begin{pmatrix}
        b \\ d
    \end{pmatrix})\\
    &=det(\begin{pmatrix}
        a \\ 0
    \end{pmatrix}+\begin{pmatrix}
        0 \\ c
    \end{pmatrix}, \begin{pmatrix}
        b \\ d
    \end{pmatrix})\\
    &=det(\begin{pmatrix}
        a \\ 0
    \end{pmatrix}, \begin{pmatrix}
        b \\ d
    \end{pmatrix})+det(\begin{pmatrix}
        0 \\ c
    \end{pmatrix}, \begin{pmatrix}
        b \\ d
    \end{pmatrix})\tag{by Multilinearity}\\
    &=det(\begin{pmatrix}
        a \\ 0
    \end{pmatrix}, \begin{pmatrix}
        b \\ 0
    \end{pmatrix}+\begin{pmatrix}
        0 \\ d
    \end{pmatrix})+det(\begin{pmatrix}
        0 \\ c
    \end{pmatrix}, \begin{pmatrix}
        b \\ 0
    \end{pmatrix}+\begin{pmatrix}
        0 \\ d
    \end{pmatrix})\\
    &=det(\begin{pmatrix}
        a \\ 0
    \end{pmatrix}, \begin{pmatrix}
        b \\ 0
    \end{pmatrix})+det(\begin{pmatrix}
        a \\ 0
    \end{pmatrix}, \begin{pmatrix}
        0 \\ d
    \end{pmatrix})+det(\begin{pmatrix}
        0 \\ c
    \end{pmatrix}, \begin{pmatrix}
        b \\ 0
    \end{pmatrix})+det(\begin{pmatrix}
        0 \\ c
    \end{pmatrix}, \begin{pmatrix}
        0 \\ d
    \end{pmatrix})\tag{by Multilinearity}\\
    &=det(\begin{bmatrix}
        a & b \\
        0 & 0
    \end{bmatrix})+det(\begin{bmatrix}
        a & 0 \\
        0 & d
    \end{bmatrix})+det(\begin{bmatrix}
        0 & b \\
        c & 0
    \end{bmatrix})+det(\begin{bmatrix}
        0 & 0 \\
        c & d
    \end{bmatrix})
    \end{align*}
    Let's figure what the determinants of each of these matrices are. We want to figure out how to reach each of them from the identity since we know the determinant of the identity and we know what specific operations do to the determinant. 
    
    For the first matrix, we start by scaling the second column of the identity by $0$. We now have the matrix $\begin{bmatrix}
        1 & 0\\
        0 & 0
    \end{bmatrix}$ which has determinant equal to $0$. Then we scale the first column by $a$ to get $\begin{bmatrix}
        a & 0\\
        0 & 0
    \end{bmatrix}$ which still has determinant $0$. blah blah blah. the determirnant is 0.

    Now, let's find the determinant of the second matrix. its determinant is $ad$.

    the third matrix has determinant $-bc$.

    the fourth matrix also gives $0$

    Thus, the determinant of a $2\times 2$ matrix is $ad-bc$.
\end{example}
\begin{lemma}
    Let $A$ be an $n\times n$ matrix and $E$ be a $n\times n$ elementary matrix then $det(AE)=det(A)det(E)$.
\end{lemma}
\begin{proof}
    just check lol
\end{proof}
\begin{theorem}
    Let $A$ be a $n\times n$ matrix. $A$ is invertible if and only if $det(A)\neq 0$.
\end{theorem}
\begin{proof}
    Since $A$ is invertible, $A=E_kE_{k-1}\ldots E_1 I$. We know the determinants of the elementary matrices and none of them are zero. Thus, $det(A)=det(E_k E_{k-1}\ldots E_1)$ and by the above lemma and induction we get that $det(E_k E_{k-1}\ldots E_1)=det(E_k)det(E_{k-1})\ldots det(E_1)\neq 0$.

    Assume $det(A)=0$
\end{proof}
\begin{lemma}
    Let $A$ and $B$ be $n\times n$ matrices. If either $A$ is not invertible or $B$ is not invertible, then $AB$ is not invertible.
\end{lemma}
\begin{theorem}
    Let $A$ and $B$ be $n\times n$ matrices then $det(AB)=det(A)det(B)$.
\end{theorem}
\begin{proof}
    If either $A$ is not invertible or $B$ is not invertible then by Lemma 3.1.8, $AB$ is not invertible. Thus, by Theorem 3.1.7, $det(AB)=det(A)det(B)=0$.

    Otherwise, $A$ and $B$ are both invertible. Let $A=E_k\ldots E_1I$ and $B=F_j\ldots F_1I$ where $E$ and $F$ are elementary matrices.
    \begin{align*}
        det(AB)&=det(E_k\ldots E_1 F_j\ldots F_1)\\
        &=det(E_k\ldots E_1F_j\ldots F_2)det(F_1)\tag{by Lemma 18.6}\\
        &=det(E_k\ldots E_1F_j\ldots F_3)det(F_2)det(F_1)\tag{by Lemma 18.6}\\
        &\vdots\\
        &=det(E_k)\ldots det(E_1)det(F_j)\ldots det(F_1)\\
        &=det(E_k\ldots E_1)det(F_j\ldots F_1)\\
        &=det(A)det(B)
    \end{align*}
\end{proof}
\section{Exercises 6}
\begin{exercise}
    Prove that the determinant of a lower/upper triangular matrix is the product of the entries along its main diagonal.
\end{exercise}
\begin{exercise}
    Let $A$ be a $n\times n$ matrix. Prove that $det(A)=0$ in all of the following cases:
    \begin{enumerate}
        \item $A$ has a column of $0$'s
        \item $A$ has two equal columns
        \item The columns of $A$ are linearly dependent
    \end{enumerate}
\end{exercise}
\begin{exercise}
    Let $A$ be a $n\times n$ invertible matrix. Prove that $det(A)=\frac{1}{det(A^{-1})}$
\end{exercise}